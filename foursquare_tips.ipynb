{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "foursquare-tips",
      "provenance": [],
      "collapsed_sections": [
        "7Iela9r7n0-w",
        "9-xOfQ08vC6z",
        "OIylpfff8g_N",
        "Vwy6OWfLyVsa",
        "qntxCNOJ8N2W",
        "Jb-O7olh8R2g",
        "jZQkbrMO8WCo"
      ],
      "authorship_tag": "ABX9TyN5z+lHyixlkbtLqnaFMIkp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduartheinen/foursquare-tips/blob/master/foursquare_tips.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Iela9r7n0-w"
      },
      "source": [
        "#**TODO/Table of Contents:**\n",
        "1. [x] **Data Preprocessing**\n",
        "2. [x] **Feature Engineering:**\n",
        ">BOW, TF-IDF, LSA, Class-Balanced Loss;\n",
        "3. [x] **ML Models:**\n",
        ">Naive Bayes, Logistic Regression, SVM, XGBoost;\n",
        "4. [ ] **Deep Learning Models:**\n",
        "> Bi-LSTM (learns, but sequential data would be better), \n",
        ">\n",
        "> BERT fine tunning (future work);\n",
        "5. [x] **GridSearch:**\n",
        "> Cross validated combination of best parameters and features;\n",
        "6. [ ] **Plot and Discuss Results**\n",
        "> visualize  accuracy, precision, recall and f1 metrics with box plots for each model and configuration, Confusion-Matrix, plot ROC-AUC\n",
        "7. [ ] **Model/Decision interpretation with LIME**\n",
        "8. [ ] **EMOJIS**\n",
        "9. [ ] **Análise de Frequência de Termos -- Classes Positiva e Negativa**\n",
        "> Comparação antes e depois tf-idf\n",
        "10. [ ] **Nuvem de Palavras**\n",
        "11. [ ] **Comparação bi-tri-gramas**\n",
        "12. [ ] **Apresentar predição**\n",
        "13. [ ] **Artigos para sustentar escolhas**\n",
        "14. [ ] **Explicar diferença entre modelos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44FLg7CDfD-g",
        "collapsed": true,
        "outputId": "c1986ed9-d416-464a-d4fc-ff4ad37d7f28"
      },
      "source": [
        "!pip install -U spacy setuptools wheel xgboost plotly chart-studio # ipyml transformers\n",
        "!python -m spacy download pt_core_news_sm # comment this line after first run"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.7/dist-packages (53.1.0)\n",
            "Requirement already up-to-date: wheel in /usr/local/lib/python3.7/dist-packages (0.36.2)\n",
            "Requirement already up-to-date: xgboost in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already up-to-date: plotly in /usr/local/lib/python3.7/dist-packages (4.14.3)\n",
            "Requirement already up-to-date: chart-studio in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.1)\n",
            "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: pathy in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "2021-02-28 00:33:42.537818: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Requirement already satisfied: pt-core-news-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.0.0/pt_core_news_sm-3.0.0-py3-none-any.whl#egg=pt_core_news_sm==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from pt-core-news-sm==3.0.0) (3.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (8.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (53.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy<3.1.0,>=3.0.0->pt-core-news-sm==3.0.0) (3.0.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK-h5BIoZAfP"
      },
      "source": [
        "# uncomment only if using BERT\n",
        "# !wget https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip\n",
        "# !wget https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/vocab.txt -P bert_checkpoint/\n",
        "# !unzip bert-base-portuguese-cased_pytorch_checkpoint.zip -d bert_checkpoint/"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r6-1fBl--hf"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2, SelectKBest\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-xOfQ08vC6z"
      },
      "source": [
        "#**0. Foursquare Tips Dataset**\n",
        "Composed of user reviews in portuguese, referring to localities of São Paulo/Brazil and collected with the Foursquare API from the categories: Food, Shop & Service and Nightlife Spot. \n",
        "\n",
        ">```dataset_test.csv``` has a total of 179,181 reviews.\n",
        ">\n",
        ">```tips_scenario1_train.csv``` contains 1708 reviews labeled as **negative, neutral or positive**.\n",
        ">\n",
        ">```tips_scenario2_train.csv``` contains 1788 reviews labeled as **negative or positive**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "pWtGDY8S5FFf",
        "cellView": "form",
        "outputId": "bb947e1f-1cd9-4d1c-b063-6fd430456643"
      },
      "source": [
        "#@title\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/eduartheinen/foursquare-tips/master/data/'\n",
        "\n",
        "df1 = pd.read_csv(path + 'tips_scenario1_train.csv').dropna(how='any')\n",
        "df2 = pd.read_csv(path + 'tips_scenario2_train.csv').dropna(how='any')\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, subplot_titles=(\"Scenario 1\",\"Scenario 2\"))\n",
        "\n",
        "fig.add_trace(go.Bar(x=['negative', 'neutral', 'positive'],\n",
        "                     y=[len(df1[df1.rotulo==c]) for c in df1.rotulo.unique()],\n",
        "                     marker_color=['red', 'gray', 'blue']),\n",
        "              row=1, col=1)\n",
        "\n",
        "fig.add_trace(go.Bar(x=['negative', 'positive'],\n",
        "                     y=[len(df2[df2.rotulo==c]) for c in df2.rotulo.unique()],\n",
        "                     marker_color=['red', 'blue']), \n",
        "              row=1, col=2)\n",
        "    \n",
        "fig.update_layout(autosize=False, showlegend=False, width=1000, height=500, title='Samples Distribution')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"d2b58035-3378-45f5-b20c-b57500d72588\" class=\"plotly-graph-div\" style=\"height:500px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d2b58035-3378-45f5-b20c-b57500d72588\")) {                    Plotly.newPlot(                        \"d2b58035-3378-45f5-b20c-b57500d72588\",                        [{\"marker\": {\"color\": [\"red\", \"gray\", \"blue\"]}, \"type\": \"bar\", \"x\": [\"negative\", \"neutral\", \"positive\"], \"xaxis\": \"x\", \"y\": [414, 133, 1161], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"red\", \"blue\"]}, \"type\": \"bar\", \"x\": [\"negative\", \"positive\"], \"xaxis\": \"x2\", \"y\": [886, 902], \"yaxis\": \"y2\"}],                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Scenario 1\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Scenario 2\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"autosize\": false, \"height\": 500, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Samples Distribution\"}, \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d2b58035-3378-45f5-b20c-b57500d72588');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIylpfff8g_N"
      },
      "source": [
        "# **1. Data Preprocessing**\n",
        "\n",
        "- Raw dataset entries contain a sentence of 30 words, followed by its label.\n",
        "\n",
        "- After removing urls, punctuation marks and numbers, each sentence is processed with the **SpaCy NLP API**, trained in Portuguese.\n",
        "\n",
        "- This step tokenizes and adds properties to each term of the sentence;\n",
        "\n",
        "- Properties as:\n",
        ">   **```lemma_```** return the word's canonical form, \n",
        ">\n",
        ">   **```pos_```** it's part of speech tag (noun, verb, adjective, ...),\n",
        ">\n",
        ">   **```is_stop```** determine if it is a stop word.\n",
        "\n",
        "- **For instance,** the sentence:\n",
        "> \"Eu fui morar na Estação da Luz. Porque estava muito escuro dentro do meu coração\"\n",
        "\n",
        "- **...would become**:\n",
        "> ```tokens = ['morar', 'estação', 'luz', 'escuro', 'coração']```\n",
        ">\n",
        "> ```lemmas = ['morar', 'estação', 'luzir', 'escuro', 'coração']```\n",
        ">\n",
        "> ```pos = ['VERB', 'NOUN', 'NOUN', 'ADJ', 'NOUN']```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UO5uc8i8mRE"
      },
      "source": [
        "#**2. Feature Engineering**\n",
        "\n",
        "One of the first fundamental choices involded in the construction of a Machine/Deep Learning Model is the representation of real world observations as features that can be read and understood by the model.\n",
        "\n",
        "The **observations** in the dataset are **sentence with 30 words** followed by a **label** that indicates the **overall sentiment** of that sentence.\n",
        "\n",
        "As the sentences are user reviews written in portuguese, they retain the subjective and flexible nature of colloquial language. Thus, an ideal machine learning model should be able to map not only the correlation between words and labels, but their context and it's effects on the sentence's meaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwy6OWfLyVsa"
      },
      "source": [
        "##2.1 Text Representation: Bag of Words and TF-IDF\n",
        "\n",
        "![bow.png](https://i.imgur.com/TTjtkUH.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2rC4569MbMQ"
      },
      "source": [
        "##2.2 Single Value Decomposition and Latent Semantic Analysis\n",
        "![lsa.png](https://i.imgur.com/EMWATJX.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_GEj9iqEw2i",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "class FoursquareTipsDataset():\n",
        "    def __init__(self, df, ngram_range=None):\n",
        "      # extracting lemmas and POS tags with spacy even though we are not using them yet\n",
        "      self.sentences, self.terms, self.lemmas, self.pos = self.preprocess(df.texto)\n",
        "      self.labels = df.rotulo.reset_index(drop=True)\n",
        "      self.feature_type_ = 'bow'\n",
        "\n",
        "      # bag of words\n",
        "      self.count_vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
        "      self.bow = self.count_vectorizer.fit_transform(self.sentences)\n",
        "\n",
        "      # tfidf\n",
        "      self.tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_df=0.99, min_df=0.002) # removed if present in less than 3.6 documents\n",
        "      self.tfidf = self.tfidf_vectorizer.fit_transform(self.sentences)\n",
        "\n",
        "      # SVD/LSA\n",
        "      print('fitting bow_lsa')\n",
        "      self.svd_bow = self.fit_svd_bow(self.bow)\n",
        "      print('fitting tfidf_lsa')\n",
        "      self.svd_tfidf = self.fit_svd_tfidf(self.tfidf)\n",
        "\n",
        "      # for easy indexing\n",
        "      self.sentences = pd.DataFrame(self.sentences)\n",
        "      self.lemmas = pd.DataFrame(self.lemmas)\n",
        "      self.pos = pd.DataFrame(self.pos)\n",
        "\n",
        "    def feature_type(self, feature_type):\n",
        "      self.feature_type_ = feature_type\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(reviews):\n",
        "        sentences = []\n",
        "        lemmas = []\n",
        "        pos = []\n",
        "        terms = []\n",
        "\n",
        "        for sentence in tqdm(reviews):\n",
        "            sentence = re.sub(r'http\\S+', '', sentence)  # removes urls before punctuation\n",
        "            punctuation_to_space = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
        "            sentence = sentence.translate(punctuation_to_space)  # change punctuations to spaces\n",
        "            sentence = str.lower(sentence)\n",
        "            sentence = re.sub('\\d+', '', sentence)  # removes numbers\n",
        "            sentence = re.sub(' +', ' ', sentence)  # removes double spaces\n",
        "\n",
        "            # spacy processing -- nlp(sentence) -- adds properties to words,\n",
        "            # like \"lemma_\", \"pos_\" and \"is_stop\" for stop_words.\n",
        "            sentence = list(filter(lambda w: not w.is_stop, nlp(sentence)))\n",
        "            lemmas.append([w.lemma_ for w in sentence if not w.is_stop])\n",
        "            pos.append([w.pos_ for w in sentence if not w.is_stop])\n",
        "            terms.append(sentence)\n",
        "\n",
        "            # sklearn count/tfidf vectorizers require raw text\n",
        "            sentences.append(' '.join([w.text for w in sentence]))\n",
        "\n",
        "        return sentences, terms, lemmas, pos\n",
        "\n",
        "    def fit_svd_bow(self, data):\n",
        "      for c in range(1400, 2000, 100):\n",
        "        svd = TruncatedSVD(n_components=c, n_iter=10)\n",
        "        svd.fit(data)\n",
        "        if svd.explained_variance_ratio_.sum() > 0.98:\n",
        "          break\n",
        "      print(f'{c} components explained {svd.explained_variance_ratio_.sum():.4f} of feature variance.')\n",
        "      return svd.fit_transform(data)\n",
        "\n",
        "    def fit_svd_tfidf(self, data):\n",
        "      for c in range(1, data.shape[1], 20):\n",
        "        svd = TruncatedSVD(n_components=c, n_iter=10)\n",
        "        svd.fit(data)\n",
        "        if svd.explained_variance_ratio_.sum() > 0.98:\n",
        "          break\n",
        "      print(f'{c} components explained {svd.explained_variance_ratio_.sum():.4f} of feature variance.')\n",
        "      return svd.fit_transform(data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      if self.feature_type_ == 'svd_tfidf':\n",
        "        return self.svd_tfidf[i], self.labels.iloc[i]\n",
        "\n",
        "      if self.feature_type_ == 'svd_bow':\n",
        "        return self.svd_bow[i], self.labels.iloc[i]\n",
        "\n",
        "      if self.feature_type_ == 'tfidf':\n",
        "        return self.tfidf[i].toarray(), self.labels.iloc[i]\n",
        "\n",
        "      return self.bow[i].toarray(), self.labels.iloc[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL5KFp4V_Ldz"
      },
      "source": [
        "##\\<Load and Process Dataset\\>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtphWQXGFyy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "99e36420-5e2a-467b-9946-93a165be9fcf"
      },
      "source": [
        "#@title\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "path = 'https://raw.githubusercontent.com/eduartheinen/foursquare-tips/master/data/'\n",
        "\n",
        "df = pd.read_csv(path + 'tips_scenario1_train.csv').dropna(how='any')\n",
        "data = FoursquareTipsDataset(df, ngram_range=(1, 2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1708/1708 [00:14<00:00, 117.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fitting bow_lsa\n",
            "1500 components explained 0.9880 of feature variance.\n",
            "fitting tfidf_lsa\n",
            "861 components explained 0.9819 of feature variance.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTM1MExXTl1f"
      },
      "source": [
        "##2.3 Class-Balanced Loss Based on Effective Number of Samples\n",
        "https://openaccess.thecvf.com/content_CVPR_2019/papers/Cui_Class-Balanced_Loss_Based_on_Effective_Number_of_Samples_CVPR_2019_paper.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fWXj7YQY_aw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "cellView": "form",
        "outputId": "8ed71c1a-a360-4d2f-9942-c4deaf5ed42e"
      },
      "source": [
        "#@title\n",
        "N = data.bow.shape[0] * data.bow.shape[1]\n",
        "beta = (N - 1) / N\n",
        "num_classes = 2\n",
        "samples_per_class = [len(data.labels[data.labels == -1]), \\\n",
        "                     len(data.labels[data.labels == 1])]\n",
        "\n",
        "effective_num = 1.0 - np.power(beta, samples_per_class)\n",
        "weights = (1.0 - beta) / np.array(effective_num)\n",
        "weights = weights / np.sum(weights) * num_classes\n",
        "\n",
        "scaled_class_samples = [len(df1[df1.rotulo==c]) for c in df1.rotulo.unique()]\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2, shared_yaxes=True, subplot_titles=(\"Original\",\"Scaled Proportionally to Samples\"))\n",
        "fig.add_trace(go.Bar(x=['negative', 'neutral', 'positive'],\n",
        "                     y=scaled_class_samples,\n",
        "                     marker_color=['red', 'gray', 'blue']),\n",
        "              row=1, col=1)\n",
        "\n",
        "scaled_class_samples[0] = scaled_class_samples[0] * weights[0]\n",
        "scaled_class_samples[2] = scaled_class_samples[2] * weights[1]\n",
        "\n",
        "fig.add_trace(go.Bar(x=['negative', 'neutral', 'positive'],\n",
        "                     y=scaled_class_samples,\n",
        "                     marker_color=['red', 'gray', 'blue']), \n",
        "              row=1, col=2)\n",
        "    \n",
        "fig.update_layout(autosize=False, showlegend=False, width=1000, height=500, title='Samples Distribution')\n",
        "\n",
        "# class_weights = {-1:weights[0], 0:1, 1:weights[1]}\n",
        "class_weights = {-1:weights[0], 1:weights[1]}\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"cfcebddd-b123-4f16-8422-b12cac7daace\" class=\"plotly-graph-div\" style=\"height:500px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cfcebddd-b123-4f16-8422-b12cac7daace\")) {                    Plotly.newPlot(                        \"cfcebddd-b123-4f16-8422-b12cac7daace\",                        [{\"marker\": {\"color\": [\"red\", \"gray\", \"blue\"]}, \"type\": \"bar\", \"x\": [\"negative\", \"neutral\", \"positive\"], \"xaxis\": \"x\", \"y\": [414, 133, 1161], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"red\", \"gray\", \"blue\"]}, \"type\": \"bar\", \"x\": [\"negative\", \"neutral\", \"positive\"], \"xaxis\": \"x2\", \"y\": [610.3524064710224, 133, 610.359555766046], \"yaxis\": \"y2\"}],                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Original\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Scaled Proportionally to Samples\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"autosize\": false, \"height\": 500, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Samples Distribution\"}, \"width\": 1000, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.45]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cfcebddd-b123-4f16-8422-b12cac7daace');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3ydL6YZNotO"
      },
      "source": [
        "#**3. Probabilistic and Machine Learning Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-4YIGNvH1Wo"
      },
      "source": [
        "## 3.1 Naive Bayes\n",
        "\n",
        "![lsa.png](https://i.imgur.com/dyhj5yi.png)\n",
        "\n",
        "https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0PTHABiH0pB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5cca36-1a38-459c-da84-c5c45a47aed8"
      },
      "source": [
        "from sklearn.naive_bayes import ComplementNB\n",
        "features = ['bow', 'tfidf']\n",
        "scores = {f:[] for f in features}\n",
        "\n",
        "for f in features:\n",
        "  data.feature_type(f)\n",
        "  kf = KFold(n_splits=10, shuffle=True)\n",
        "  for train_index, test_index in kf.split(range(0, len(data))):\n",
        "    x_train, y_train = data[train_index]\n",
        "    x_test, y_test = data[test_index]\n",
        "    \n",
        "    cnb = ComplementNB()\n",
        "    cnb.fit(x_train, y_train)\n",
        "    scores[f].append(cnb.score(x_test, y_test))\n",
        "\n",
        "cnb_scores = scores\n",
        "nb_bow = np.mean(scores['bow'])\n",
        "nb_tfidf = np.mean(scores['tfidf'])\n",
        "scores"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bow': [0.7134502923976608,\n",
              "  0.6549707602339181,\n",
              "  0.672514619883041,\n",
              "  0.672514619883041,\n",
              "  0.5906432748538012,\n",
              "  0.695906432748538,\n",
              "  0.5964912280701754,\n",
              "  0.7192982456140351,\n",
              "  0.6941176470588235,\n",
              "  0.6588235294117647],\n",
              " 'tfidf': [0.7251461988304093,\n",
              "  0.7426900584795322,\n",
              "  0.7543859649122807,\n",
              "  0.7309941520467836,\n",
              "  0.695906432748538,\n",
              "  0.7192982456140351,\n",
              "  0.6842105263157895,\n",
              "  0.7192982456140351,\n",
              "  0.7235294117647059,\n",
              "  0.7529411764705882]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "danFZrBn8JxY"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdsoFJcxA8mE"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "features = ['bow', 'svd_bow', 'tfidf', 'svd_tfidf']\n",
        "\n",
        "scores = {f:[] for f in features}\n",
        "scores.update({f+'_weighted':[] for f in features})\n",
        "\n",
        "for f in features:\n",
        "  data.feature_type(f)\n",
        "  kf = KFold(n_splits=10, shuffle=True)\n",
        "  for train_index, test_index in kf.split(range(0, len(data))):\n",
        "    x_train, y_train = data[train_index]\n",
        "    x_test, y_test = data[test_index:]\n",
        "\n",
        "    lr_cv = LogisticRegression(C=1e3, n_jobs=-1, max_iter=500)\n",
        "    lr_cv.fit(x_train, y_train)\n",
        "    scores[f].append(lr_cv.score(x_test, y_test))\n",
        "\n",
        "    lr_cv = LogisticRegression(C=1, n_jobs=-1, max_iter=500, \n",
        "                                class_weight=class_weights)\n",
        "    lr_cv.fit(x_train, y_train)\n",
        "    scores[f+'_weighted'].append(lr_cv.score(x_test, y_test))\n",
        "\n",
        "lr_scores = scores\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qntxCNOJ8N2W"
      },
      "source": [
        "#Support Vector Classification\n",
        "\n",
        "Data that is not linearly separable in its original dimension space can be projected into a higher-dimensional space with a kernel function. \n",
        "\n",
        "This function takes as input vectors in the original space and returns the dot product of the vectors in the higher-dimensional feature space.\n",
        "\n",
        "![lsa.png](https://miro.medium.com/max/913/1*gXvhD4IomaC9Jb37tzDUVg.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qPHhIXc8Rcu"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "features = ['bow', 'svd_bow', 'tfidf', 'svd_tfidf']\n",
        "\n",
        "scores = {f:[] for f in features}\n",
        "scores.update({f+'_weighted':[] for f in features})\n",
        "\n",
        "train_index = test_index = int(len(data)*0.75) # testing with 0.15 of dataset\n",
        "# for train_index, test_index in kf.split(data.bow):\n",
        "for f in features:\n",
        "  x_train, y_train = data[:train_index]\n",
        "  x_test, y_test = data[test_index:]\n",
        "\n",
        "  scv = SVC(kernel='poly', C=1.0)\n",
        "  scv.fit(x_train, y_train)\n",
        "  scores[f].append(scv.score(x_test, y_test))\n",
        "\n",
        "  scv = SVC(kernel='poly', C=1.0, class_weight=class_weights)\n",
        "  scv.fit(x_train, y_train)\n",
        "  scores[f+'_weighted'].append(scv.score(x_test, y_test))\n",
        "\n",
        "svc_scores = scores\n",
        "\n",
        "for f in features:\n",
        "  tmp = np.mean(scores[f])\n",
        "  print(f'{f}:{tmp}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-O7olh8R2g"
      },
      "source": [
        "#XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT1LcLA38VsY"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "features = ['bow', 'svd_bow', 'tfidf', 'svd_tfidf']\n",
        "\n",
        "scores = {f:[] for f in features}\n",
        "scores.update({f+'_weighted':[] for f in features})\n",
        "\n",
        "# train_index = test_index = int(len(data)*0.75) # testing with 0.15 of dataset\n",
        "for train_index, test_index in kf.split(data.bow):\n",
        "  for f in features:\n",
        "    data.feature_type(f)\n",
        "    x_train, y_train = data[train_index]\n",
        "    x_test, y_test = data[test_index]\n",
        "\n",
        "    xgb = XGBClassifier()\n",
        "    xgb.fit(x_train, y_train)\n",
        "    scores[f].append(xgb.score(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZQkbrMO8WCo"
      },
      "source": [
        "#Bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNNi2zcxLTM5"
      },
      "source": [
        "\"\"\"#Bi-directional LSTM\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_index = test_index = int(len(data) * 0.75)  # testing with 0.15 of dataset\n",
        "hidden_dim = 64\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.01\n",
        "max_epochs = 100\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # GloVe, but contains only vectors that refer to words on the dataset vocabulary\n",
        "        # self.word_embeds = nn.Embedding.from_pretrained(embedding_vectors)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        # Maps the output of the LSTM into label space.\n",
        "        self.hidden2label = nn.Linear(hidden_dim, num_classes)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.nn.init.xavier_uniform_(torch.zeros(2, 1, self.hidden_dim // 2)).to(device),\n",
        "                torch.nn.init.xavier_uniform_(torch.zeros(2, 1, self.hidden_dim // 2)).to(device))\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        # as of batch_first=True requires input shape (batch, seq, feature)\n",
        "        sentence = sentence.view(1, 1, len(sentence))\n",
        "        lstm_out, _ = self.lstm(sentence, self.hidden)\n",
        "        lstm_feats = self.hidden2label(lstm_out)\n",
        "        labels = F.log_softmax(lstm_feats[0], dim=1)\n",
        "\n",
        "        return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s56bt37LqeQQ"
      },
      "source": [
        "def training_epoch(model, optimizer, train_x, train_y):  # criterion, scheduler\n",
        "    model.train()\n",
        "    losses = []\n",
        "    progress_bar = tqdm(range(len(train_x)), desc='Training', leave=False)\n",
        "    for i in progress_bar:\n",
        "        inputs = torch.Tensor(train_x[i]).to(device)\n",
        "        target = torch.LongTensor([0 if train_y[i] == -1 else 1]).to(device)\n",
        "\n",
        "        # Clean old gradients\n",
        "        # optimizer.zero_grad()\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forwards pass\n",
        "        output = model(inputs)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # acc = accuracy_score(model, output)\n",
        "\n",
        "        # Perform gradient descent, backwards pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Take a step in the right direction\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    # plot_losses(losses, 'batch #', 'neg_log_likelihood_loss', 'Training Loss')\n",
        "    return sum(losses) / len(losses)\n",
        "\n",
        "\n",
        "def validate_epoch(model, test_x, test_y):  # criterion, scheduler\n",
        "    model.eval()\n",
        "    output = []\n",
        "    targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(range(len(test_x)), desc='Validating', leave=False)\n",
        "        for i in progress_bar:\n",
        "            inputs = torch.Tensor(test_x[i]).to(device)\n",
        "\n",
        "            # Forwards pass\n",
        "            output.append(model(inputs)[0].tolist())  # TODO: save only data, ignore tensors\n",
        "            targets.append([1, 0] if test_y[i] == -1 else [0, 1])\n",
        "\n",
        "            # Calculating the F-Score\n",
        "            # positive = [i for i, t in enumerate(target.view(-1)) if t != 0]\n",
        "            # predictions = (target - best_path).view(-1)\n",
        "            # true_positive = [i for i, t in enumerate(predictions[positive]) if t == 0]\n",
        "\n",
        "            # if len(true_positive) > 0:\n",
        "            #     p = len(true_positive) / len(predictions)\n",
        "            #     r = len(true_positive) / len(positive)\n",
        "            #     mean_F.append(2 * p * r / (p + r))\n",
        "\n",
        "    # mean_F = np.mean(mean_F)\n",
        "    # return mean_F if mean_F > best_F else best_F\n",
        "    # return np.mean(mean_F)\n",
        "\n",
        "    return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I31Ia6PCFwh"
      },
      "source": [
        "model = BiLSTM(data.bow.shape[1], hidden_dim, num_classes).to(device)\n",
        "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                        lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "loss_file = 'losses.csv'\n",
        "train_losses = []\n",
        "best_Fs = []\n",
        "best_F = 0\n",
        "epoch = 0\n",
        "\n",
        "# resume training\n",
        "checkpoint_file = 'ner-bilstm-crf-feb20.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO3Y2r7P5oWf"
      },
      "source": [
        "# training epochs\n",
        "for epoch in range(max_epochs):\n",
        "    train_loss = training_epoch(model, optimizer, train_loader)  # train_loader\n",
        "    new_F = validate_epoch(model, valid_loader)\n",
        "\n",
        "    if new_F > best_F:\n",
        "        best_F = new_F\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      torch.save({\n",
        "          'epoch': epoch,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'train_losses': train_losses,\n",
        "          'best_Fs': best_Fs\n",
        "      }, checkpoint_file)\n",
        "        \n",
        "\n",
        "    # with open(loss_file, 'a', newline='\\n') as csvfile:\n",
        "    #     writer = csv.writer(csvfile)\n",
        "    #     writer.writerow([epoch + 1, train_loss, new_F])\n",
        "\n",
        "    tqdm.write(\n",
        "        f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.6f}\\tcurrent_F: {new_F:.6f}\\tbest_F: {best_F:.6f} \\n',\n",
        "    )\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    best_Fs.append(new_F)\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "plot_losses(train_losses, 'training epoch #', 'neg_log_likelihood_loss', 'Training Loss')\n",
        "plot_losses(best_Fs, 'validation epoch #', 'F score', 'F score')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}